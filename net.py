{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DPhzaQGks7x"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sklearn.metrics as met\n",
    "\n",
    "\n",
    "import torch.nn.init as init\n",
    "from torchvision.models.squeezenet import *\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Add, Activation, Concatenate, Conv2D, Dropout \n",
    "from keras.layers import Flatten, Input, GlobalAveragePooling2D, MaxPooling2D\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkBsRLHKrSbW"
   },
   "outputs": [],
   "source": [
    "#DenseNet: Inspired by the framework of B.Amos \"https://github.com/bamos/densenet.pytorch.git\"\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, nChannels, growthRate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        interChannels = 4*growthRate\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.conv1 = nn.Conv2d(nChannels, interChannels, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(interChannels)\n",
    "        self.conv2 = nn.Conv2d(interChannels, growthRate, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "\n",
    "class SingleLayer(nn.Module):\n",
    "    def __init__(self, nChannels, growthRate):\n",
    "        super(SingleLayer, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.conv1 = nn.Conv2d(nChannels, growthRate, kernel_size=3,\n",
    "                               padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = torch.cat((x, out), 1)\n",
    "        return out\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, nChannels, nOutChannels):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.conv1 = nn.Conv2d(nChannels, nOutChannels, kernel_size=1,\n",
    "                               bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growthRate, depth, reduction, nClasses, bottleneck):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        nDenseBlocks = (depth-4) // 3\n",
    "        if bottleneck:\n",
    "            nDenseBlocks //= 2\n",
    "\n",
    "        nChannels = 2*growthRate\n",
    "        self.conv1 = nn.Conv2d(3, nChannels, kernel_size=3, padding=1,\n",
    "                               bias=False)\n",
    "        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels*reduction))\n",
    "        self.trans1 = Transition(nChannels, nOutChannels)\n",
    "\n",
    "        nChannels = nOutChannels\n",
    "        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels*reduction))\n",
    "        self.trans2 = Transition(nChannels, nOutChannels)\n",
    "\n",
    "        nChannels = nOutChannels\n",
    "        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n",
    "        nChannels += nDenseBlocks*growthRate\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels)\n",
    "        self.fc = nn.Linear(nChannels, nClasses)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_dense(self, nChannels, growthRate, nDenseBlocks, bottleneck):\n",
    "        layers = []\n",
    "        for i in range(int(nDenseBlocks)):\n",
    "            if bottleneck:\n",
    "                layers.append(Bottleneck(nChannels, growthRate))\n",
    "            else:\n",
    "                layers.append(SingleLayer(nChannels, growthRate))\n",
    "            nChannels += growthRate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        out = self.dense3(out)\n",
    "        out = torch.squeeze(F.avg_pool2d(F.relu(self.bn1(out)), 8))\n",
    "        out = F.log_softmax(self.fc(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bmwe7nc1zP0N"
   },
   "outputs": [],
   "source": [
    "# ResNet14: Inspired by frameworks of Yuan \"https://github.com/itsyuanyuan/BirdCLEF2019.git\" \n",
    "# and J.Chou \"https://github.com/Mipanox/Bird_cocktail.git\"  \n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, channels, stride=1, downsample=None, padding=1):\n",
    "       super(Block, self).__init__()\n",
    "       self.conv1 = nn.Conv2d(in_channels, channels,kernel_size=3, stride=stride, padding=padding, bias=False)\n",
    "       self.bn1 = nn.BatchNorm2d(channels)\n",
    "       self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=padding, bias=False)\n",
    "       self.bn2 = nn.BatchNorm2d(channels)\n",
    "       self.downsample = downsample\n",
    "       self.stride = stride\n",
    "\n",
    "    def forward(self, s):\n",
    "        residual = s \n",
    "        out = self.conv1(s) \n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(s)\n",
    "        sys.stdout.flush()\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZWYr0Caz4AT"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, params, num_classes):\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        layers = [2,2,2,2]\n",
    "        self.num_channels = params.num_channels\n",
    "        self.inchannels   = params.num_channels\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,self.inchannels, kernel_size=3, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inchannels)\n",
    "\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        self.layer1 = self._make_layer(Block,  self.num_channels,layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(Block,2*self.num_channels,layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(Block,4*self.num_channels,layers[2], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(4,stride=1)\n",
    "        self.fc1 = nn.Linear(2*128*int(np.ceil(params.width/128.))*2, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, channels, num_layers, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannels != channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inchannels, channels,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channels),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inchannels, channels, stride, downsample))\n",
    "        self.inchannels = channels\n",
    "        for i in range(1, num_layers):\n",
    "            layers.append(block(self.inchannels, channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = self.conv1(s)\n",
    "        s = self.bn1(s)\n",
    "        s = F.relu(s)\n",
    "        s = self.maxpool(s)\n",
    "        s = self.layer1(s)\n",
    "        s = self.layer2(s)\n",
    "        s = self.layer3(s)\n",
    "        s = self.avgpool(s)\n",
    "        s = s.view(s.size(0),-1)\n",
    "        return self.fc1(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpK9yJ5GzGB-"
   },
   "outputs": [],
   "source": [
    "#SqueezeNet: Inspired by framework of J.Chou \"https://github.com/Mipanox/Bird_cocktail.git\" \n",
    "def SqueezeNet(input_shape, nb_classes, dropout_rate=None, compression=1.0):\n",
    "\n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(int(64*compression), (3,3), activation='relu', strides=(2,2), padding='same', name='conv1')(input_img)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool1')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(16*compression), name='fire2')\n",
    "    x = create_fire_module(x, int(16*compression), name='fire3')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool3')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(32*compression), name='fire4')\n",
    "    x = create_fire_module(x, int(32*compression), name='fire5')\n",
    "    \n",
    "    x = MaxPooling2D(pool_size=(3,3), strides=(2,2), name='maxpool5')(x)\n",
    "    \n",
    "    x = create_fire_module(x, int(48*compression), name='fire6')\n",
    "    x = create_fire_module(x, int(48*compression), name='fire7')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire8')\n",
    "    x = create_fire_module(x, int(64*compression), name='fire9')\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    # Creating last conv10\n",
    "    x = output(x, nb_classes)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=x)\n",
    "\n",
    "\n",
    "def output(x, nb_classes):\n",
    "    x = Conv2D(nb_classes, (1,1), strides=(1,1), padding='valid', name='conv10')(x)\n",
    "    x = GlobalAveragePooling2D(name='avgpool10')(x)\n",
    "    x = Activation(\"softmax\", name='softmax')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_fire_module(x, nb_squeeze_filter, name, use_bypass=False):\n",
    "\n",
    "    nb_expand_filter = 4 * nb_squeeze_filter\n",
    "    squeeze    = Conv2D(nb_squeeze_filter,(1,1), activation='relu', padding='same', name='%s_squeeze'%name)(x)\n",
    "    expand_1x1 = Conv2D(nb_expand_filter, (1,1), activation='relu', padding='same', name='%s_expand_1x1'%name)(squeeze)\n",
    "    expand_3x3 = Conv2D(nb_expand_filter, (3,3), activation='relu', padding='same', name='%s_expand_3x3'%name)(squeeze)\n",
    "    \n",
    "    axis = get_axis()\n",
    "    x_ret = Concatenate(axis=axis, name='%s_concatenate'%name)([expand_1x1, expand_3x3])\n",
    "    \n",
    "    if use_bypass:\n",
    "        x_ret = Add(name='%s_concatenate_bypass'%name)([x_ret, x])\n",
    "        \n",
    "    return x_ret\n",
    "\n",
    "def get_axis():\n",
    "    axis = -1 if K.image_data_format() == 'channels_last' else 1\n",
    "    return axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzIueYDGrfEc"
   },
   "outputs": [],
   "source": [
    "#Inception-v4 Net: Inspired by framework of R.Cadene \"https://github.com/Cadene/tensorflow-model-zoo.torch.git\"\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n",
    "        self.bn = nn.BatchNorm2d(out_planes, eps=0.001, momentum=0, affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paoL0z54rqkY"
   },
   "outputs": [],
   "source": [
    "class Mixed(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.maxpool(x)\n",
    "        x1 = self.conv(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaM7QNXkrzbU"
   },
   "outputs": [],
   "source": [
    "class Inception_A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_A, self).__init__()\n",
    "        self.branch0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(384, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(384, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlhpsEL3sKpD"
   },
   "outputs": [],
   "source": [
    "class Reduction_A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Reduction_A, self).__init__()\n",
    "        self.branch0 = BasicConv2d(384, 384, kernel_size=1, stride=2)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(384, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(224, 256, kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRd9TXXqskRu"
   },
   "outputs": [],
   "source": [
    "class Inception_B(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_B, self).__init__()\n",
    "        self.branch0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(224, 256, kernel_size=(7,1), stride=1, padding=(3,0))\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(224, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(224, 256, kernel_size=(1,7), stride=1, padding=(0,3))\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFR3Ix59tbSw"
   },
   "outputs": [],
   "source": [
    "class Reduction_B(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Reduction_B, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(320, 320, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvYMHrH_uGmD"
   },
   "outputs": [],
   "source": [
    "class Inception_C(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_C, self).__init__()\n",
    "\n",
    "        self.branch0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n",
    "        \n",
    "        self.branch1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n",
    "        self.branch1_1a = BasicConv2d(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.branch1_1b = BasicConv2d(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        \n",
    "        self.branch2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n",
    "        self.branch2_1 = BasicConv2d(384, 448, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        self.branch2_2 = BasicConv2d(448, 512, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.branch2_3a = BasicConv2d(512, 256, kernel_size=(3,1), stride=1, padding=(0,1))\n",
    "        self.branch2_3b = BasicConv2d(512, 256, kernel_size=(1,3), stride=1, padding=(1,0))\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(1536, 256, kernel_size=3, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        \n",
    "        x1_0 = self.branch1_0(x)\n",
    "        x1_1a = self.branch1_1a(x1_0)\n",
    "        x1_1b = self.branch1_1b(x1_0)\n",
    "        x1 = torch.cat((x1_1a, x1_1b), 1)\n",
    "\n",
    "        x2_0 = self.branch2_0(x)\n",
    "        x2_1 = self.branch2_1(x2_0)\n",
    "        x2_2 = self.branch2_2(x2_1)\n",
    "        x2_3a = self.branch2_3a(x2_2)\n",
    "        x2_3b = self.branch2_3b(x2_2)\n",
    "        x2 = torch.cat((x2_3a, x2_3b), 1)\n",
    "\n",
    "        x3 = self.branch3(x)\n",
    "\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CCn4AqiuYaN"
   },
   "outputs": [],
   "source": [
    "class InceptionNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Reference: https://arxiv.org/pdf/1602.07261.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, params, num_classes):\n",
    "        super(InceptionNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            BasicConv2d(3 , 32, kernel_size=3, stride=2),\n",
    "            BasicConv2d(32, 32, kernel_size=3, stride=1),\n",
    "            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            Mixed(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Reduction_A(), \n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Reduction_B(),\n",
    "            Inception_C(),\n",
    "            Inception_C(),\n",
    "            Inception_C(),\n",
    "            nn.AvgPool2d(2, count_include_pad=False)\n",
    "        )\n",
    "        self.classif = nn.Linear(1536, num_classes)\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = self.features(s)\n",
    "        s = s.view(s.size(0), -1)\n",
    "        s = self.classif(s) \n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKOxmK3J2oOD"
   },
   "outputs": [],
   "source": [
    "def precision(outputs, labels, threshold):\n",
    "\n",
    "    outputs = F.sigmoid(outputs).data.gt(threshold).cpu().numpy()\n",
    "    labels  = labels.data.cpu().numpy()\n",
    "    prec = np.mean([met.precision_score(labels[i], outputs[i]) for i in range(labels.shape[0])])\n",
    "    return prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PgFFhjXxiDVt"
   },
   "outputs": [],
   "source": [
    "def apk( actual, predicted, k=11):\n",
    "\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtIcJeuex6GU"
   },
   "outputs": [],
   "source": [
    "def mapk(actual, predicted, k=11):\n",
    "   \n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4UwItN9m4Q7Y"
   },
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(outputs, labels):\n",
    "\n",
    "    return nn.CrossEntropyLoss()(outputs, labels.long())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
